import sounddevice as sd
import queue
import json
from vosk import Model, KaldiRecognizer

# ëª¨ë¸ ê²½ë¡œ ì§€ì • (ì˜ˆ: ./vosk-model-small-ko-0.22)
MODEL_PATH = "./model/vosk-model-small-ko-0.22"

print(sd.query_devices())

# ìƒ˜í”Œë ˆì´íŠ¸ (ë³´í†µ 16kHz)
SAMPLE_RATE = 16000
DEVICE_ID = 2  # âœ… ë§ˆì´í¬(OMEN Cam & Voice)

# ëª¨ë¸ ë¡œë“œ
model = Model(MODEL_PATH)
recognizer = KaldiRecognizer(model, SAMPLE_RATE)

# ì˜¤ë””ì˜¤ ìŠ¤íŠ¸ë¦¼ í
q = queue.Queue()

def callback(indata, frames, time, status):
    if status:
        print(status, flush=True)
    q.put(bytes(indata))

# ì˜¤ë””ì˜¤ ì…ë ¥ ìŠ¤íŠ¸ë¦¼ ì—´ê¸°
with sd.RawInputStream(samplerate=SAMPLE_RATE,
                       blocksize=8000,
                       dtype='int16',
                       channels=1,
                       device=DEVICE_ID,
                       callback=callback):
    print("ğŸ™ï¸ ë§í•˜ì„¸ìš” (ì¢…ë£Œí•˜ë ¤ë©´ Ctrl+C)")
    while True:
        data = q.get()
        if recognizer.AcceptWaveform(data):
            result = recognizer.Result()
            text = json.loads(result).get("text", "")
            if text:
                print("ğŸ—£ï¸ ì¸ì‹ ê²°ê³¼:", text)
        else:
            partial = recognizer.PartialResult()
            partial_text = json.loads(partial).get("partial", "")
            if partial_text:
                print("âŒ› ì¸ì‹ ì¤‘:", partial_text, end="\r")


# import sounddevice as sd
# import numpy as np

# def print_volume(indata, frames, time, status):
#     volume = np.linalg.norm(indata) * 10
#     print(f"ë³¼ë¥¨: {volume:.2f}")

# DEVICE_ID = 1  # ë§ˆì´í¬(OMEN Cam & Voice)
# SAMPLE_RATE = 16000

# with sd.InputStream(channels=1, samplerate=SAMPLE_RATE,
#                     device=DEVICE_ID, callback=print_volume):
#     print("ë§í•˜ë©´ ë³¼ë¥¨ì´ ë‚˜ì™€ì•¼ í•¨ (Ctrl+C ì¢…ë£Œ)")
#     import time
#     while True:
#         time.sleep(0.1)
